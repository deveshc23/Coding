{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quotes=pd.read_csv('trades_USDC_OKEX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure sysTimestamp is in datetime format\n",
    "df_quotes['sysTimestamp'] = pd.to_datetime(df_quotes['sysTimestamp'])\n",
    "\n",
    "# Filter data for the first hour\n",
    "first_hour_data = df_quotes[df_quotes['sysTimestamp'] < df_quotes['sysTimestamp'].iloc[0] + pd.Timedelta(hours=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_hour_data.to_csv('trades_USDC_O.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "def flatten_trade(record):\n",
    "    \"\"\"Flatten a trade (T) message.\"\"\"\n",
    "    return {\n",
    "        \"exp\": record.get(\"exp\"),\n",
    "        \"sysTimestamp\": record.get(\"header\", {}).get(\"sysTimestamp\"),\n",
    "        \"side\": record.get(\"side\"),\n",
    "        \"price\": record.get(\"p\"),\n",
    "        \"quantity\": record.get(\"q\"),\n",
    "        # \"tradeId\": record.get(\"tradeId\"),\n",
    "        \"OutTs\": record.get(\"OutTs\"),\n",
    "        \"ActTs\": record.get(\"ActTs\")\n",
    "    }\n",
    "\n",
    "def flatten_quote(record):\n",
    "    \"\"\"Flatten a quote (Q) message.\"\"\"\n",
    "    bid = record.get(\"bid\", {})\n",
    "    ask = record.get(\"ask\", {})\n",
    "    return {\n",
    "        \"exp\": record.get(\"exp\"),\n",
    "        \"sysTimestamp\": record.get(\"header\", {}).get(\"sysTimestamp\"),\n",
    "        \"bid_price\": bid.get(\"p\"),\n",
    "        \"bid_quantity\": bid.get(\"q\"),\n",
    "        \"bid_c\": bid.get(\"c\"),\n",
    "        \"ask_price\": ask.get(\"p\"),\n",
    "        \"ask_quantity\": ask.get(\"q\"),\n",
    "        \"ask_c\": ask.get(\"c\"),\n",
    "        \"Seq\": record.get(\"Seq\"),\n",
    "        \"ActTs\": record.get(\"ActTs\"),\n",
    "        \"OutTs\": record.get(\"OutTs\")\n",
    "    }\n",
    "\n",
    "def flatten_snapshot(record):\n",
    "    \"\"\"Flatten a snapshot (S) message.\"\"\"\n",
    "    rows = []\n",
    "    exp = record.get(\"exp\")\n",
    "    sysTimestamp = record.get(\"header\", {}).get(\"sysTimestamp\")\n",
    "    snapshot_timestamp = record.get(\"timestamp\")\n",
    "    \n",
    "    # Process bids: mark these rows with order_type \"bid\"\n",
    "    for order in record.get(\"bids\", []):\n",
    "        row = {\n",
    "            \"exp\": exp,\n",
    "            \"sysTimestamp\": sysTimestamp,\n",
    "            \"snapshot_timestamp\": snapshot_timestamp,\n",
    "            \"order_type\": \"bid\",\n",
    "            \"price\": order.get(\"p\"),\n",
    "            \"quantity\": order.get(\"q\")\n",
    "        }\n",
    "        rows.append(row)\n",
    "    \n",
    "    # Process asks: mark these rows with order_type \"ask\"\n",
    "    for order in record.get(\"asks\", []):\n",
    "        row = {\n",
    "            \"exp\": exp,\n",
    "            \"sysTimestamp\": sysTimestamp,\n",
    "            \"snapshot_timestamp\": snapshot_timestamp,\n",
    "            \"order_type\": \"ask\",\n",
    "            \"price\": order.get(\"p\"),\n",
    "            \"quantity\": order.get(\"q\")\n",
    "        }\n",
    "        rows.append(row)\n",
    "    \n",
    "    return rows\n",
    "\n",
    "def segregate_data(json_file_path):\n",
    "    \"\"\"\n",
    "    Read the file line-by-line and segregate the records by message type:\n",
    "    trades (T), quotes (Q), snapshots (S).\n",
    "    \"\"\"\n",
    "    trades = []\n",
    "    quotes = []\n",
    "    snapshots = []\n",
    "    \n",
    "    with open(json_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                msg_type = data.get(\"header\", {}).get(\"type\")\n",
    "                if msg_type == \"T\":\n",
    "                    trades.append(data)\n",
    "                elif msg_type == \"Q\":\n",
    "                    quotes.append(data)\n",
    "                elif msg_type == \"S\":\n",
    "                    snapshots.append(data)\n",
    "                else:\n",
    "                    print(f\"Unknown message type: {msg_type}\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return trades, quotes, snapshots\n",
    "\n",
    "def process_records(trades, quotes, snapshots):\n",
    "    \"\"\"Flatten and convert each type of message to a DataFrame.\"\"\"\n",
    "    # Flatten trade messages\n",
    "    flat_trades = [flatten_trade(rec) for rec in trades]\n",
    "    df_trades = pd.DataFrame(flat_trades)\n",
    "    \n",
    "    # Flatten quote messages\n",
    "    flat_quotes = [flatten_quote(rec) for rec in quotes]\n",
    "    df_quotes = pd.DataFrame(flat_quotes)\n",
    "    \n",
    "    # Flatten snapshot messages:\n",
    "    flat_snapshot_rows = []\n",
    "    for rec in snapshots:\n",
    "        flat_snapshot_rows.extend(flatten_snapshot(rec))\n",
    "    df_snapshots = pd.DataFrame(flat_snapshot_rows)\n",
    "    \n",
    "    return df_trades, df_quotes, df_snapshots\n",
    "\n",
    "def flatten_data(df):\n",
    "    \"\"\"Flatten the data.\"\"\"\n",
    "    df_trades = df[df['msg_type'] == 'T']\n",
    "    df_quotes = df[df['msg_type'] == 'Q']\n",
    "    df_snapshots = df[df['msg_type'] == 'S']\n",
    "\n",
    "    df_trades = df_trades.apply(flatten_trade, axis=1, result_type='expand')\n",
    "    df_quotes = df_quotes.apply(flatten_quote, axis=1, result_type='expand')\n",
    "    df_snapshots = df_snapshots.apply(flatten_snapshot, axis=1, result_type='expand')\n",
    "\n",
    "    return df_trades, df_quotes, df_snapshots\n",
    "\n",
    "def convert_df_timestamps(df, columns):\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col].astype(float), unit='ns', errors='coerce')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Path to the top-level \"BINANCE_SPOT\" folder that contains subfolders (e.g. 000002, 230000, etc.)\n",
    "    base_dir = \"C:/Users/choud/.ipython/Downloads/Sample1/OKEX_SPOT\"\n",
    "    \n",
    "    # Create lists to hold partial DataFrames from each data.json\n",
    "    all_trades = []\n",
    "    all_quotes = []\n",
    "    all_snapshots = []\n",
    "    \n",
    "    # Loop over each subfolder in BINANCE_SPOT (e.g. 000002, 230000, etc.)\n",
    "    for folder_name in os.listdir(base_dir):\n",
    "        folder_path = os.path.join(base_dir, folder_name)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            # Inside each numeric folder, there's a BTC folder containing data.json\n",
    "            btc_folder = os.path.join(folder_path, \"SOL\")\n",
    "            if os.path.isdir(btc_folder):\n",
    "                data_file = os.path.join(btc_folder, \"data.json\")\n",
    "                if os.path.isfile(data_file):\n",
    "                    print(f\"Processing: {data_file}\")\n",
    "                    \n",
    "                    # 1) Segregate data\n",
    "                    trades, quotes, snapshots = segregate_data(data_file)\n",
    "                    \n",
    "                    # 2) Flatten into DataFrames\n",
    "                    df_trades, df_quotes, df_snapshots = process_records(trades, quotes, snapshots)\n",
    "                    \n",
    "                    # 3) Convert timestamps\n",
    "                    df_trades = convert_df_timestamps(df_trades, [\"sysTimestamp\", \"ActTs\", \"OutTs\"])\n",
    "                    df_quotes = convert_df_timestamps(df_quotes, [\"sysTimestamp\", \"ActTs\", \"OutTs\"])\n",
    "                    df_snapshots = convert_df_timestamps(df_snapshots, [\"sysTimestamp\", \"snapshot_timestamp\"])\n",
    "                    \n",
    "                    # 4) Append to global lists\n",
    "                    all_trades.append(df_trades)\n",
    "                    all_quotes.append(df_quotes)\n",
    "                    all_snapshots.append(df_snapshots)\n",
    "    \n",
    "    # Concatenate all partial DataFrames into final ones\n",
    "    final_trades = pd.concat(all_trades, ignore_index=True) if all_trades else pd.DataFrame()\n",
    "    final_quotes = pd.concat(all_quotes, ignore_index=True) if all_quotes else pd.DataFrame()\n",
    "    final_snapshots = pd.concat(all_snapshots, ignore_index=True) if all_snapshots else pd.DataFrame()\n",
    "    \n",
    "    # Print or save\n",
    "    print(\"\\n--- Final Trades DataFrame ---\")\n",
    "    print(final_trades.head())\n",
    "    \n",
    "    print(\"\\n--- Final Quotes DataFrame ---\")\n",
    "    print(final_quotes.head())\n",
    "    \n",
    "    print(\"\\n--- Final Snapshots DataFrame ---\")\n",
    "    print(final_snapshots.head())\n",
    "    \n",
    "    # Save to CSV if desired\n",
    "    final_trades.to_csv(\"trades_SOL_OKEX.csv\", index=False)\n",
    "    final_quotes.to_csv(\"quotes_SOL_OKEX.csv\", index=False)\n",
    "    final_snapshots.to_csv(\"snapshots_SOL_OKEX.csv\", index=False)\n",
    "    print(\"\\nAll data saved to trades.csv, quotes.csv, snapshots.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
